# !/usr/bin/env python3
# -*- coding: utf-8 -*-
from flask import (
    Flask,
    url_for,
    session,
    jsonify,
    request,
    redirect,
    Response,
    render_template,
    send_from_directory,
    stream_with_context,
)
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import subprocess
import hashlib
import logging
import json
import os
import sys
import asyncio
import threading
from datetime import datetime


from drama_classifier import extract_drama_name, classify_drama
from task_handlers import register_all_handlers
from telegram_queue_manager import add_task
from extensions import scheduler  # å¯¼å…¥å…±äº«çš„ scheduler å®ä¾‹

# æ·»åŠ å½“å‰ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from db import db_session
from model.cloud_resource import CloudResource
from model.tmdb import Tmdb
from resource_manager import ResourceManager


def get_app_ver():
    BUILD_SHA = os.environ.get("BUILD_SHA", "")
    BUILD_TAG = os.environ.get("BUILD_TAG", "")
    if BUILD_TAG[:1] == "v":
        return BUILD_TAG
    elif BUILD_SHA:
        return f"{BUILD_TAG}({BUILD_SHA[:7]})"
    else:
        return "dev"


# æ–‡ä»¶è·¯å¾„
PYTHON_PATH = "python3" if os.path.exists("/usr/bin/python3") else "python"
SCRIPT_PATH = os.environ.get("SCRIPT_PATH", "./quark_auto_save.py")
CONFIG_PATH = os.environ.get("CONFIG_PATH", "./quark_config.json")
DEBUG = os.environ.get("DEBUG", False)

# è·å–é¡¹ç›®æ ¹ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PUBLIC_DIR = os.path.join(BASE_DIR, "public")

# åˆ›å»º Flask åº”ç”¨ï¼ŒæŒ‡å®š public ç›®å½•
app = Flask(__name__,
            static_folder=os.path.join(PUBLIC_DIR, "static"),
            template_folder=os.path.join(PUBLIC_DIR, "templates"))
app.config["APP_VERSION"] = get_app_ver()
app.secret_key = os.environ.get("FLASK_SECRET_KEY", "quark_auto_save_secret_key")
app.json.ensure_ascii = False
app.json.sort_keys = False
app.jinja_env.variable_start_string = "[["
app.jinja_env.variable_end_string = "]]"


# åœ¨æ¯ä¸ªè¯·æ±‚ç»“æŸåæ¸…ç†æ•°æ®åº“ session
@app.teardown_appcontext
def shutdown_session(exception=None):
    if exception:
        db_session.rollback()
    db_session.remove()


# åŸæœ‰çš„ BackgroundSchedulerï¼Œç”¨äº quark_auto_save.py è„šæœ¬è°ƒåº¦
bg_scheduler = BackgroundScheduler()

logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format="[%(asctime)s][%(levelname)s] %(message)s",
    datefmt="%m-%d %H:%M:%S",
)
# è¿‡æ»¤werkzeugæ—¥å¿—è¾“å‡º
if not DEBUG:
    logging.getLogger("werkzeug").setLevel(logging.ERROR)


def gen_md5(string):
    md5 = hashlib.md5()
    md5.update(string.encode("utf-8"))
    return md5.hexdigest()


# è¯»å– JSON æ–‡ä»¶å†…å®¹
def read_json():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data


# å°†æ•°æ®å†™å…¥ JSON æ–‡ä»¶
def write_json(data):
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, ensure_ascii=False, sort_keys=False)


def is_login():
    data = read_json()
    username = data["webui"]["username"]
    password = data["webui"]["password"]
    if session.get("login") == gen_md5(username + password):
        return True
    else:
        return False


# è®¾ç½®icon
@app.route("/favicon.ico")
def favicon():
    return send_from_directory(
        app.static_folder,
        "favicon.ico",
        mimetype="image/vnd.microsoft.icon",
    )


# ç™»å½•é¡µé¢
@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        data = read_json()
        username = data["webui"]["username"]
        password = data["webui"]["password"]
        # éªŒè¯ç”¨æˆ·åå’Œå¯†ç 
        if (username == request.form.get("username")) and (
                password == request.form.get("password")
        ):
            logging.info(f">>> ç”¨æˆ· {username} ç™»å½•æˆåŠŸ")
            session["login"] = gen_md5(username + password)
            return redirect(url_for("index"))
        else:
            logging.info(f">>> ç”¨æˆ· {username} ç™»å½•å¤±è´¥")
            return render_template("login.html", message="ç™»å½•å¤±è´¥")

    return render_template("login.html", error=None)


# é€€å‡ºç™»å½•
@app.route("/logout")
def logout():
    session.pop("login", None)
    return redirect(url_for("login"))


# ç®¡ç†é¡µé¢
@app.route("/")
def index():
    if not is_login():
        return redirect(url_for("login"))
    return render_template("index.html", version=app.config["APP_VERSION"])


# è·å–é…ç½®æ•°æ®
@app.route("/data")
def get_data():
    if not is_login():
        return redirect(url_for("login"))
    data = read_json()
    del data["webui"]
    return jsonify(data)


# æ›´æ–°æ•°æ®
@app.route("/update", methods=["POST"])
def update():
    if not is_login():
        return "æœªç™»å½•"
    data = read_json()
    webui = data["webui"]
    data = request.json
    data["webui"] = webui
    write_json(data)
    # é‡æ–°åŠ è½½ä»»åŠ¡
    if reload_tasks():
        logging.info(f">>> é…ç½®æ›´æ–°æˆåŠŸ")
        return "é…ç½®æ›´æ–°æˆåŠŸ"
    else:
        logging.info(f">>> é…ç½®æ›´æ–°å¤±è´¥")
        return "é…ç½®æ›´æ–°å¤±è´¥"


# å¤„ç†è¿è¡Œè„šæœ¬è¯·æ±‚
@app.route("/run_script_now", methods=["GET"])
def run_script_now():
    if not is_login():
        return "æœªç™»å½•"
    task_index = request.args.get("task_index", "")
    command = [PYTHON_PATH, "-u", SCRIPT_PATH, CONFIG_PATH, task_index]
    logging.info(
        f">>> æ‰‹åŠ¨è¿è¡Œä»»åŠ¡{int(task_index) + 1 if task_index.isdigit() else 'all'}"
    )

    def generate_output():
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1,
        )
        try:
            for line in iter(process.stdout.readline, ""):
                logging.info(line.strip())
                yield f"data: {line}\n\n"
            yield "data: [DONE]\n\n"
        finally:
            process.stdout.close()
            process.wait()

    return Response(
        stream_with_context(generate_output()),
        content_type="text/event-stream;charset=utf-8",
    )


# å®šæ—¶ä»»åŠ¡æ‰§è¡Œçš„å‡½æ•°
def run_python(args):
    logging.info(f">>> å®šæ—¶è¿è¡Œä»»åŠ¡")
    os.system(f"{PYTHON_PATH} {args}")


# é‡æ–°åŠ è½½ä»»åŠ¡
def reload_tasks():
    # è¯»å–æ•°æ®
    data = read_json()
    # æ·»åŠ æ–°ä»»åŠ¡
    crontab = data.get("crontab")
    if crontab:
        if bg_scheduler.state == 1:
            bg_scheduler.pause()  # æš‚åœè°ƒåº¦å™¨
        trigger = CronTrigger.from_crontab(crontab)
        bg_scheduler.remove_all_jobs()
        bg_scheduler.add_job(
            run_python,
            trigger=trigger,
            args=[f"{SCRIPT_PATH} {CONFIG_PATH}"],
            id=SCRIPT_PATH,
        )
        if bg_scheduler.state == 0:
            bg_scheduler.start()
        elif bg_scheduler.state == 2:
            bg_scheduler.resume()
        scheduler_state_map = {0: "åœæ­¢", 1: "è¿è¡Œ", 2: "æš‚åœ"}
        logging.info(">>> é‡è½½è°ƒåº¦å™¨")
        logging.info(f"è°ƒåº¦çŠ¶æ€: {scheduler_state_map[bg_scheduler.state]}")
        logging.info(f"å®šæ—¶è§„åˆ™: {crontab}")
        logging.info(f"ç°æœ‰ä»»åŠ¡: {bg_scheduler.get_jobs()}")
        return True
    else:
        logging.info(">>> no crontab")
        return False


def init():
    logging.info(f">>> åˆå§‹åŒ–é…ç½®")
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CONFIG_PATH):
        if not os.path.exists(os.path.dirname(CONFIG_PATH)):
            os.makedirs(os.path.dirname(CONFIG_PATH))
        with open("quark_config.json", "rb") as src, open(CONFIG_PATH, "wb") as dest:
            dest.write(src.read())
    data = read_json()
    # é»˜è®¤ç®¡ç†è´¦å·
    if not data.get("webui"):
        data["webui"] = {
            "username": "admin",
            "password": "admin123",
        }
    elif os.environ.get("WEBUI_USERNAME") and os.environ.get("WEBUI_PASSWORD"):
        data["webui"] = {
            "username": os.environ.get("WEBUI_USERNAME"),
            "password": os.environ.get("WEBUI_PASSWORD"),
        }
    # é»˜è®¤å®šæ—¶è§„åˆ™
    if not data.get("crontab"):
        data["crontab"] = "0 8,18,20 * * *"
    write_json(data)


# èµ„æºç®¡ç†é¡µé¢
@app.route("/resources")
def resources():
    if not is_login():
        return redirect(url_for("login"))
    return render_template("resources.html", version=app.config["APP_VERSION"])


# è·å–èµ„æºåˆ—è¡¨
@app.route("/api/resources")
def get_resources():
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        page = request.args.get("page", 1, type=int)
        per_page = request.args.get("per_page", 20, type=int)
        sort_by = request.args.get("sort_by", "update_time")
        order = request.args.get("order", "desc")
        is_expired = request.args.get("is_expired", "0")
        search = request.args.get("search", "")

        # æ„å»ºæŸ¥è¯¢
        query = db_session.query(CloudResource, Tmdb).outerjoin(
            Tmdb, CloudResource.tmdb_id == Tmdb.id
        )

        # è¿‡æ»¤æ¡ä»¶
        if is_expired != "all":
            query = query.filter(CloudResource.is_expired == int(is_expired))

        if search:
            query = query.filter(
                (CloudResource.drama_name.like(f"%{search}%")) |
                (CloudResource.alias.like(f"%{search}%"))
            )

        # æ’åº
        sort_column = getattr(CloudResource, sort_by, CloudResource.update_time)
        if order == "desc":
            query = query.order_by(sort_column.desc())
        else:
            query = query.order_by(sort_column.asc())

        # åˆ†é¡µ
        total = query.count()
        resources = query.limit(per_page).offset((page - 1) * per_page).all()

        # æ ¼å¼åŒ–ç»“æœ
        result = []
        for resource, tmdb in resources:
            item = resource.to_dict()
            item["tmdb"] = tmdb.to_dict() if tmdb else None
            result.append(item)

        return jsonify({
            "total": total,
            "page": page,
            "per_page": per_page,
            "data": result
        })
    except Exception as e:
        db_session.rollback()
        logging.error(f"æŸ¥è¯¢èµ„æºå¤±è´¥: {str(e)}")
        return jsonify({"error": f"æŸ¥è¯¢å¤±è´¥: {str(e)}"}), 500


# ä¸€é”®æŠ•ç¨¿åˆ°Telegram
@app.route("/api/share_to_tg/<int:resource_id>", methods=["POST"])
def share_to_tg(resource_id):
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        # è·å–ç¬¬ä¸€ä¸ªcookie
        cookie = os.environ.get("QUARK_COOKIE", "")
        if not cookie:
            data = read_json()
            cookie = data.get("quark_cookie", "")
        if not cookie:
            return jsonify({"error": "æœªé…ç½®å¤¸å…‹Cookie"}), 400

        # åˆ›å»ºèµ„æºç®¡ç†å™¨
        manager = ResourceManager(cookie)

        # åœ¨åå°äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡
        if queue_loop and queue_loop.is_running():
            # ä½¿ç”¨ asyncio.run_coroutine_threadsafe åœ¨åå°äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œ
            future = asyncio.run_coroutine_threadsafe(
                manager.shareToTgBot(resource_id),
                queue_loop
            )
            # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆè®¾ç½®è¶…æ—¶ï¼‰
            result = future.result(timeout=10)

            if result:
                return jsonify({"success": True, "message": "ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—"})
            else:
                return jsonify({"error": "ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—å¤±è´¥"}), 500
        else:
            return jsonify({"error": "é˜Ÿåˆ—ç®¡ç†å™¨æœªè¿è¡Œ"}), 500

    except Exception as e:
        db_session.rollback()
        logging.error(f"æŠ•ç¨¿å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# æ›´æ–°èµ„æºçŠ¶æ€
@app.route("/api/resources/<int:resource_id>/status", methods=["PUT"])
def update_resource_status(resource_id):
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        data = request.json
        is_expired = data.get("is_expired")

        resource = db_session.query(CloudResource).filter(
            CloudResource.id == resource_id
        ).first()

        if not resource:
            return jsonify({"error": "èµ„æºä¸å­˜åœ¨"}), 404

        resource.is_expired = is_expired
        db_session.commit()

        return jsonify({"success": True, "message": "æ›´æ–°æˆåŠŸ"})
    except Exception as e:
        db_session.rollback()
        logging.error(f"æ›´æ–°å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500


# è·å–é˜Ÿåˆ—çŠ¶æ€
@app.route("/api/queue_status", methods=["GET"])
def get_queue_status():
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        import telegram_queue_manager as qm

        # åœ¨åå°äº‹ä»¶å¾ªç¯ä¸­è·å–çŠ¶æ€
        async def get_status():
            return qm.get_status()

        if queue_loop and queue_loop.is_running():
            future = asyncio.run_coroutine_threadsafe(get_status(), queue_loop)
            status = future.result(timeout=5)
            return jsonify({"success": True, "status": status})
        else:
            return jsonify({"error": "é˜Ÿåˆ—ç®¡ç†å™¨æœªè¿è¡Œ"}), 500

    except Exception as e:
        logging.error(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# å¤¸å…‹ç½‘ç›˜èµ„æºé¡µé¢
@app.route("/quark_files")
def quark_files():
    if not is_login():
        return redirect(url_for("login"))
    return render_template("quark_files.html", version=app.config["APP_VERSION"])


# è·å–å¤¸å…‹ç½‘ç›˜æ–‡ä»¶åˆ—è¡¨
@app.route("/api/quark/ls_dir", methods=["GET"])
def quark_ls_dir():
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        pdir_fid = request.args.get("pdir_fid", "0")

        # è·å–cookie
        cookie = os.environ.get("QUARK_COOKIE", "")
        if not cookie:
            data = read_json()
            cookie = data.get("quark_cookie", "")
        if not cookie:
            return jsonify({"error": "æœªé…ç½®å¤¸å…‹Cookie"}), 400

        # åˆ›å»º Quark å®ä¾‹
        from quark_auto_save import Quark
        quark = Quark(cookie, index=0)

        if not quark.init():
            return jsonify({"error": "å¤¸å…‹è´¦å·éªŒè¯å¤±è´¥"}), 400

        # è·å–æ–‡ä»¶åˆ—è¡¨
        files = quark.ls_dir(pdir_fid)

        if files is None:
            return jsonify({"error": "è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥"}), 500

        return jsonify({"success": True, "files": files})

    except Exception as e:
        logging.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# åˆ†äº«å¹¶ä¿å­˜èµ„æºåˆ°æ•°æ®åº“
@app.route("/api/quark/share_and_save", methods=["POST"])
def quark_share_and_save():
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        data = request.json
        fid = data.get("fid")
        file_name = data.get("file_name")
        is_dir = data.get("is_dir", False)

        if not fid or not file_name:
            return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400

        item_type = "æ–‡ä»¶å¤¹" if is_dir else "æ–‡ä»¶"
        logging.info(f"å¼€å§‹å¤„ç†{item_type}: {file_name} (fid: {fid})")

        # è·å–cookie
        cookie = os.environ.get("QUARK_COOKIE", "")
        if not cookie:
            config_data = read_json()
            cookie = config_data.get("quark_cookie", "")
        if not cookie:
            return jsonify({"error": "æœªé…ç½®å¤¸å…‹Cookie"}), 400

        # åˆ›å»º Quark å®ä¾‹
        from quark_auto_save import Quark
        quark = Quark(cookie, index=0)

        if not quark.init():
            return jsonify({"error": "å¤¸å…‹è´¦å·éªŒè¯å¤±è´¥"}), 400

        drama_name = extract_drama_name(file_name)
        existing_resource = db_session.query(CloudResource).filter(
            CloudResource.drama_name == drama_name,
            CloudResource.drive_type == "quark"
        ).first()
        if existing_resource:
            return jsonify({"error": f"{item_type}å·²å­˜åœ¨: {file_name}"}), 400

        # åˆ›å»ºåˆ†äº«
        logging.info(f"æ­£åœ¨åˆ†äº«{item_type}: {file_name}")
        share_result = quark.share_dir([fid], file_name)

        if not share_result or not share_result.get("share_url"):
            return jsonify({"error": f"åˆ›å»º{item_type}åˆ†äº«å¤±è´¥"}), 500

        share_url = share_result["share_url"]
        logging.info(f"âœ… {item_type}åˆ†äº«æˆåŠŸ: {share_url}")

        # åˆ›å»ºæ–°èµ„æº
        # æ ¹æ®æ˜¯å¦ä¸ºæ–‡ä»¶å¤¹è®¾ç½®åˆ†ç±»
        category2 = classify_drama(file_name)
        new_resource = CloudResource(
            drama_name=drama_name,
            alias=file_name,
            drive_type="quark",
            link=share_url,
            is_expired=0,
            category1="å½±è§†èµ„æº",
            category2=category2
        )
        db_session.add(new_resource)
        db_session.flush()
        resource_id = new_resource.id
        action = "åˆ›å»º"
        logging.info(f"åˆ›å»ºæ–°èµ„æº: {file_name} (ID: {resource_id})")

        db_session.commit()
        success_message = f"{item_type}{action}æˆåŠŸï¼"
        logging.info(f"âœ… {success_message}")

        # æ·»åŠ  TMDB æ›´æ–°ä»»åŠ¡åˆ°é˜Ÿåˆ—
        try:
            import telegram_queue_manager as qm

            # å‡†å¤‡ä»»åŠ¡æ•°æ®
            task_data = {
                "resource_id": resource_id,
                "drama_name": drama_name,
                "category": category2 if category2 in ["ç”µå½±", "å‰§é›†"] else "ç”µå½±"
            }

            # åˆ›å»ºä»»åŠ¡
            task = qm.Task(
                task_type=qm.TaskType.TMDB_UPDATE,
                task_data=task_data
            )

            # åœ¨åå°äº‹ä»¶å¾ªç¯ä¸­æ·»åŠ ä»»åŠ¡
            if queue_loop and queue_loop.is_running():
                async def add_tmdb_task():
                    return await qm.add_task(task)

                future = asyncio.run_coroutine_threadsafe(add_tmdb_task(), queue_loop)
                task_added = future.result(timeout=5)

                if task_added:
                    logging.info(f"âœ… å·²æ·»åŠ  TMDB æ›´æ–°ä»»åŠ¡: {drama_name}")
                else:
                    logging.warning(f"âš ï¸  TMDB æ›´æ–°ä»»åŠ¡æ·»åŠ å¤±è´¥: {drama_name}")
            else:
                logging.warning("âš ï¸  é˜Ÿåˆ—ç®¡ç†å™¨æœªè¿è¡Œï¼Œè·³è¿‡ TMDB æ›´æ–°ä»»åŠ¡")

        except Exception as e:
            logging.error(f"æ·»åŠ  TMDB æ›´æ–°ä»»åŠ¡å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­è¿”å›æˆåŠŸ

        return jsonify({
            "success": True,
            "message": success_message,
            "resource_id": resource_id,
            "share_url": share_url,
            "item_type": item_type,
            "action": action})
    except Exception as e:
        db_session.rollback()
        logging.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# æœç´¢TMDB
@app.route("/api/search_tmdb", methods=["GET"])
def search_tmdb():
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        query = request.args.get("query", "").strip()
        if not query:
            return jsonify({"error": "è¯·æä¾›æœç´¢å…³é”®è¯"}), 400

        # å¯¼å…¥TmdbService
        from resource_manager import TmdbService

        # åˆ›å»ºæœåŠ¡å®ä¾‹å¹¶æœç´¢
        tmdb_service = TmdbService()
        results = tmdb_service.search_multi(query, max_results=20)

        return jsonify({
            "success": True,
            "query": query,
            "results": results
        })

    except Exception as e:
        logging.error(f"æœç´¢TMDBå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# åŒ¹é…TMDBåˆ°èµ„æº
@app.route("/api/match_tmdb", methods=["POST"])
def match_tmdb():
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        data = request.json
        resource_id = data.get("resource_id")
        tmdb_id = data.get("tmdb_id")
        media_type = data.get("media_type")
        title = data.get("title")
        year_released = data.get("year_released")
        poster_path = data.get("poster_path")
        overview = data.get("overview")
        vote_average = data.get("vote_average")
        category = data.get("category")

        # éªŒè¯å¿…è¦å‚æ•°
        if not all([resource_id, tmdb_id, media_type, title]):
            return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400

        # æŸ¥æ‰¾èµ„æº
        resource = db_session.query(CloudResource).filter(
            CloudResource.id == resource_id
        ).first()

        if not resource:
            return jsonify({"error": "èµ„æºä¸å­˜åœ¨"}), 404

        # æ„å»ºæµ·æŠ¥URL
        poster_url = None
        if poster_path:
            poster_url = f"https://image.tmdb.org/t/p/w500{poster_path}"

        # è§£æå¹´ä»½
        year = None
        if year_released:
            try:
                year = int(year_released)
            except (ValueError, TypeError):
                pass

        # æŸ¥æ‰¾æˆ–åˆ›å»ºTMDBè®°å½•
        existing_tmdb = db_session.query(Tmdb).filter(
            Tmdb.tmdb_code == str(tmdb_id)
        ).first()

        if existing_tmdb:
            # æ›´æ–°ç°æœ‰è®°å½•
            existing_tmdb.title = title
            existing_tmdb.year_released = year
            existing_tmdb.description = overview or ""
            existing_tmdb.poster_url = poster_url
            existing_tmdb.category = category
            tmdb_record_id = existing_tmdb.id
            logging.info(f"æ›´æ–°TMDBè®°å½•: {title}")
        else:
            # åˆ›å»ºæ–°è®°å½•
            new_tmdb = Tmdb(
                tmdb_code=str(tmdb_id),
                title=title,
                year_released=year,
                category=category,
                description=overview or "",
                poster_url=poster_url
            )
            db_session.add(new_tmdb)
            db_session.flush()
            tmdb_record_id = new_tmdb.id
            logging.info(f"åˆ›å»ºTMDBè®°å½•: {title}")

        # å…³è”èµ„æºå’ŒTMDB
        resource.tmdb_id = tmdb_record_id
        db_session.commit()

        logging.info(f"âœ… èµ„æº '{resource.drama_name}' å·²åŒ¹é…åˆ°TMDB: {title}")

        return jsonify({
            "success": True,
            "message": "åŒ¹é…æˆåŠŸ",
            "tmdb_id": tmdb_record_id
        })

    except Exception as e:
        db_session.rollback()
        logging.error(f"åŒ¹é…TMDBå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# æ‰‹åŠ¨è§¦å‘èµ„æºé“¾æ¥æ£€æŸ¥ä»»åŠ¡
@app.route("/api/check_resources_links", methods=["POST"])
def trigger_check_resources_links():
    if not is_login():
        return jsonify({"error": "æœªç™»å½•"}), 401

    try:
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡ï¼Œé¿å…é˜»å¡è¯·æ±‚
        import threading
        from job import check_all_resources_links

        def run_check():
            try:
                check_all_resources_links()
            except Exception as e:
                logging.error(f"èµ„æºé“¾æ¥æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()

        check_thread = threading.Thread(target=run_check, daemon=True)
        check_thread.start()

        return jsonify({
            "success": True,
            "message": "èµ„æºé“¾æ¥æ£€æŸ¥ä»»åŠ¡å·²å¯åŠ¨ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¿›åº¦"
        })

    except Exception as e:
        logging.error(f"å¯åŠ¨èµ„æºé“¾æ¥æ£€æŸ¥ä»»åŠ¡å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# åå°äº‹ä»¶å¾ªç¯çº¿ç¨‹
queue_loop = None
queue_thread = None


def start_queue_manager_thread():
    """åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨é˜Ÿåˆ—ç®¡ç†å™¨"""
    global queue_loop, queue_thread

    def run_event_loop():
        """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œäº‹ä»¶å¾ªç¯"""
        global queue_loop
        try:
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            queue_loop = asyncio.new_event_loop()
            asyncio.set_event_loop(queue_loop)

            # æ³¨å†Œæ‰€æœ‰å¤„ç†å™¨å¹¶å¯åŠ¨é˜Ÿåˆ—ç®¡ç†å™¨
            queue_loop.run_until_complete(register_all_handlers())

            logging.info("âœ… é˜Ÿåˆ—ç®¡ç†å™¨å·²åœ¨åå°çº¿ç¨‹å¯åŠ¨")

            # ä¿æŒäº‹ä»¶å¾ªç¯è¿è¡Œ
            queue_loop.run_forever()

        except Exception as e:
            logging.error(f"âŒ é˜Ÿåˆ—ç®¡ç†å™¨å¯åŠ¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        finally:
            if queue_loop:
                queue_loop.close()
                logging.info("ğŸ”Œ é˜Ÿåˆ—ç®¡ç†å™¨äº‹ä»¶å¾ªç¯å·²å…³é—­")

    # åˆ›å»ºå¹¶å¯åŠ¨åå°çº¿ç¨‹
    queue_thread = threading.Thread(target=run_event_loop, daemon=True)
    queue_thread.start()
    logging.info("ğŸš€ é˜Ÿåˆ—ç®¡ç†å™¨åå°çº¿ç¨‹å·²å¯åŠ¨")


def stop_queue_manager():
    """åœæ­¢é˜Ÿåˆ—ç®¡ç†å™¨"""
    global queue_loop

    if queue_loop and queue_loop.is_running():
        logging.info("ğŸ›‘ æ­£åœ¨åœæ­¢é˜Ÿåˆ—ç®¡ç†å™¨...")
        queue_loop.call_soon_threadsafe(queue_loop.stop)


if __name__ == "__main__":
    init()
    reload_tasks()

    # é…ç½®å¹¶åˆå§‹åŒ– Flask-APScheduler
    app.config['SCHEDULER_API_ENABLED'] = True  # å¯ç”¨ API
    scheduler.init_app(app)
    scheduler.start()

    # å¯¼å…¥ job æ¨¡å—ä»¥æ³¨å†Œè£…é¥°å™¨ä»»åŠ¡
    import job
    logging.info("âœ… å®šæ—¶ä»»åŠ¡å·²æ³¨å†Œ")

    # å¯åŠ¨é˜Ÿåˆ—ç®¡ç†å™¨åå°çº¿ç¨‹
    start_queue_manager_thread()

    try:
        app.run(debug=DEBUG, host="0.0.0.0", port=5005)
    finally:
        # ç¨‹åºé€€å‡ºæ—¶åœæ­¢é˜Ÿåˆ—ç®¡ç†å™¨
        stop_queue_manager()
        # åœæ­¢ Flask-APScheduler
        if scheduler.running:
            scheduler.shutdown()
